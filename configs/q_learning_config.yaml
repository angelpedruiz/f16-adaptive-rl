# Q-Learning Agent Configuration Template
# Complete configuration for tabular Q-Learning agent training

agent:
  type: "q_learning"
  
  # Learning parameters
  learning_rate: 0.1           # Q-learning update rate
  initial_epsilon: 1.0         # Starting exploration rate
  final_epsilon: 0.05           # Final exploration rate
  epsilon_decay: 2.0e-05          # Decay rate (auto-calculated if null)
  discount_factor: 0.99        # Reward discount factor
  
  # Discretization settings
  obs_discretizer:
    type: "uniform_tile_coding"
    bins: [20, 20]  # Bins per observation dimension (1 state + 1 error = 2 dims)
  
  action_discretizer:
    type: "uniform_tile_coding"  
    bins: [1, 20]                # Bins per action dimension

environment:
  name: "f16"                  # Environment name
  
  # Environment parameters
  max_steps: 2000              # Maximum steps per episode
  dt: 0.01                     # Time step size
  
  # State configuration  
  state_indices_for_obs: [4]  # State indices for observations [pitch_rate, theta]
  
  # Action and observation bounds
  action_low: [0, -22.5]       # Action space lower bounds
  action_high: [0, 27.0]       # Action space upper bounds
  obs_low: [-1.5, -2.5]        # Observation bounds
  obs_high: [1.5, 2.5]         # Observation bounds
  
  # Reference signal configuration
  # Change 'type' to switch between: "cos_step", "sin", "constant"
  reference_config:
    1:                         # State index for reference (theta)
      type: "sin"    # Reference type: change to "sin" or "constant" as needed
      
      # COS_STEP parameters (used when type: "cos_step")
      amplitude:
        min: -0.35             # Min amplitude (radians)  
        max: 0.35             # Max amplitude (radians)
        n_levels: 15           # Number of amplitude levels
      step_duration:
        min: 5.0               # Min step duration (seconds)
        max: 5.0               # Max step duration (seconds)
        n_levels: 1            # Number of duration levels
      transition_duration:
        min: 3.0               # Min transition duration (seconds)
        max: 5.0               # Max transition duration (seconds)
        n_levels: 3            # Number of transition duration levels
      seed: null               # Random seed for sequence generation (optional)
      
      # SIN parameters (used when type: "sin")
      A: 0.35                  # Amplitude (radians)
      T: 5.0                 # Period (seconds)
      phi: 0.0                 # Phase offset (radians, optional)
      
      # CONSTANT parameters (used when type: "constant")
      value: 10.0              # Constant value (radians)

training:
  episodes: 10000             # Total training episodes
  seed: 42                     # Random seed
  log_frequency: 1000          # Log every N episodes
  detailed_logging: true      # Enable detailed logging

checkpointing:
  interval: 1000              # Checkpoint every N episodes
  keep_last_n: 3               # Keep last N checkpoints
  save_best: false              # Save best checkpoint
  resume_from: null             # Resume checkpoint path

plotting:
  enabled: true              # Enable/disable all plotting (set to false for faster training)
  
  # Training metrics
  training_metrics:
    interval: 1000           # Plot every N episodes
    rolling_window: 1000       # Rolling average window
    save_individual: true      # Save individual plots
  
  # Trajectory episodes
  trajectories:
    interval: 1000           # Interval for saving trajectory data
    episodes: [1, 30000, 60000]  # Episodes to plot trajectories
    save_data: true            # Save trajectory data
  
  # Plot settings
  figure_size: [12, 8]         # Figure dimensions
  dpi: 150                     # Resolution
  style: "seaborn"             # Plot style

evaluation:
  rolling_window: 1000         # Performance evaluation window
  convergence_threshold: 0.02  # Convergence threshold
  stability_episodes: 100      # Stability check episodes